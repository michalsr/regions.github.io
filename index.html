<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"> 
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Region-Based Representations Revisited</title>
  <link rel="apple-touch-icon" sizes="180x180" href="./icons/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="./icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="./icons/favicon-16x16.png">
  <link rel="manifest" href="./icons/site.webmanifest">

<!-- 
  Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
 

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div> -->
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div> -->

  <!-- </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Region-Based Representations Revisited</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Michal Shlapentokh-Rothman<sup>1*</sup>,</span>
            <span class="author-block">
              Ansel Blume<sup>1*</sup>,</span>
            <span class="author-block">
              Yao Xiao<sup>1</sup>,
            </span>
            <span class="author-block">
              Yuqun Wu<sup>1</sup>,
            </span>
            <span class="author-block">
              Sethuraman T V<sup>1</sup>,
            </span>
            <span class="author-block">
              Heyi Tao<sup>1</sup>,
            </span>
            <span class="author-block">
              Jae Yong Lee<sup>1</sup>,
            </span>
            <span class="author-block">
                Wilfredo Torres<sup>2</sup>,
            </span>
            <span class="author-block">
                Yu-Xiong Wang<sup>1</sup>,
            </span>
            <span class="author-block">
                Derek Hoiem<sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Illinois at Urbana-Champaign,</span>
            <span class="author-block"><sup>2</sup>Reconstruct</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
              </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="paper/paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2402.02352"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="paper/slides.pptx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-powerpoint"></i>
                  </span>
                  <span>Slides</span>
                </a>
              </span>
       
              <span class="link-block">
                <a href="https://youtu.be/_xth4y3sOmw"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> 

              <span class="link-block">
                <a href="https://github.com/michalsr/regions"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png" alt="Description of the image",class="center-margin">
      <h2 class="subtitle">
        <p>Our framework revisits the use of region features for
          downstream applications. We generate region features by first segmenting an image, extracting image features, then pooling the image features across the region masks.</p>

      </h2>
    </div>
  </div>
</section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-2">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We investigate whether region-based representations are
              effective for recognition. Regions were once a mainstay
              in recognition approaches, but pixel and patch-based features are now used almost exclusively. We show that recent class-agnostic segmenters like SAM can be effectively
              combined with strong self-supervised representations, like
              those from DINOv2, and used for a wide variety of tasks,
              including semantic segmentation, object-based image retrieval, and multi-image analysis. Once the masks and features are extracted, these representations, even with linear
              decoders, enable competitive performance, making them
              well suited to applications that require custom queries. The
              representations" compactness also makes them well-suited
              to video analysis and other problems requiring inference
              across many images          </p>
         

            </div>
        </div>
      </div>
<section>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h1 class="title is-2">How It Works</h1>
        <div class="content has-text-justified">
  
            <img src="./static/images/method.png" alt="Description of the image",class="center-margin">
            <p> Our approach is to pool image features over generated regions to create one feature vector per region, and to make predictions based on these region representations. The main steps are 
              <ol>
                <li>Extract image features. We used strong representation models like CLIP, DINOv1, DINOv2 and MaskCLIP. We found that <b>DINOv2</b> worked best.</li>
                <li>Generate regions with a class-agnostic segmenter like <a href="https://ai.meta.com/research/publications/segment-anything/">SAM.</a>
                <li>To combine the image features and generated regions, we <b>upsample</b> the extracted features and superimpose the features and regions. Then we perform <b>average</b> pooling to create the feature vectors.</li>
              </ol>
            </p>
        </div>
        <h3 class="title is-3"> Augmenting SAM with SLIC</h3>
        <div class="image-container">
          <figure>
              <img src="./static/images/sam_slic/original_sam_slic.jpg" alt="Image 1">
              <figcaption><b>Original</b></figcaption>
            </figure>
          <figure>
              <img src="./static/images/sam_slic/sam_only_sam_slic.jpg" alt="Image 2">
              <figcaption><b>SAM Only</b></figcaption>
          </figure>
          <figure>
            <img src="./static/images/sam_slic/slic.jpg" alt="Image 2">
            <figcaption><b>SLIC on unmasked regions</b></figcaption>
        </figure>
          <figure>
            <img src="./static/images/sam_slic/sam_slic_photo.jpg" alt="Image 3">
            <figcaption><b>SAM+SLIC</b></figcaption>
          </figure>
      </div>
      <p>SAM generated regions tended to leave many pixels uncovered. To improve coverage, we ran the superpixel clustering algortihm SLIC and took the intersection of SLIC and unmasked pixels. SAM+SLIC outperformed other SAM and other SAM variants such as MobileSAM and HQ-SAM. </p>
    
    <div class="grid-container">
      <div class="grid-header">SAM Only</div>
      <div class="grid-header">HQ-SAM</div>
      <div class="grid-header">Mobile-SAM(v1)</div>
      <div class="grid-header">SLIC</div>
      <div class="grid-header">SAM+SLIC</div>
      <div class="grid-item"><img src="./static/images/sam_compare/sam_only_1.jpg" alt="Image 1"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/hq_sam_1.jpg" alt="Image 2"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/mobile_sam_1.jpg" alt="Image 3"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/slic_1.jpg" alt="Image 4"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/sam_slic_1.jpg" alt="Image 5"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/sam_only_2.jpg" alt="Image 1"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/hq_sam_2.jpg" alt="Image 2"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/mobile_sam_2.jpg" alt="Image 3"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/slic_2.jpg" alt="Image 4"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/sam_slic_2.jpg" alt="Image 4"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/sam_only_3.jpg" alt="Image 1"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/hq_sam_3.jpg" alt="Image 2"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/mobile_sam_3.jpg" alt="Image 3"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/slic_3.jpg" alt="Image 4"></div>
      <div class="grid-item"><img src="./static/images/sam_compare/sam_slic_3.jpg" alt="Image 4"></div>
      <!-- Add more images as needed -->
  </div>
  </div>
  </div>
  </section> 
   
<section>
  <div class="columns is-centered has-text-centered">
    <div class="column is-full-width">
      <h1 class="title is-2">Applications</h1>
      <h2 class="title is-3">Semantic Segmentation</h2>
      <p>For semantic segmentation, we classified each region. For pixels belonging to multiple regions, we averaged the confidence. Our results outperformed corresponding patch-based models across different images features. As seen in the qualitative results, with region-based models, pixels within the same object have much more consistent classifications compared to patch-based models.</p>
      <div class="grid-container">
        <div class="grid-header">Original</div>
        <div class="grid-header">Regions (SAM+SLIC)</div>
        <div class="grid-header">Patch Model Prediction</div>
        <div class="grid-header">Region Model Prediction</div>
        <div class="grid-header">Ground Truth</div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_1/original_image.jpg" alt="Image 1"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_1/regions.jpg" alt="Image 2"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_1/baseline_preds.jpg" alt="Image 3"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_1/dino_sam_preds.jpg" alt="Image 4"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_1/gt.jpg" alt="Image 5"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_2/original_image.jpg" alt="Image 1"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_2/regions.jpg" alt="Image 2"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_2/baseline_preds.jpg" alt="Image 3"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_2/dino_sam_preds.jpg" alt="Image 4"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_2/gt.jpg" alt="Image 4"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_3/original_image.jpg" alt="Image 1"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_3/regions.jpg" alt="Image 2"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_3/baseline_preds.jpg" alt="Image 3"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_3/dino_sam_preds.jpg" alt="Image 4"></div>
        <div class="grid-item"><img src="./static/images/semantic_segmentation/ade_3/gt.jpg" alt="Image 4"></div>
        <!-- Add more images as needed -->
    </div>
    <br>
    <br>
    <h2 class="title is-3">Multi-View Semantic Segmentation</h2>
      <p>For multi-view segmentation, we trained a scene transformer on top of regions from <b>ALL</b> images in a scene. Such a transformer would require 100,000 patches but only 5,000 for scenes with an average of 100 frames/scene. Predictions from our models were generally better than the noisy ground truth.</p>
      <div class="grid-container">
        <div class="grid-header">Original</div>
        <div class="grid-header">Linear Probe</div>
        <div class="grid-header">Single Image Transformer</div>
        <div class="grid-header">Scene Transformer</div>
        <div class="grid-header">Ground Truth</div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_1/original.png" alt="Image 1"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_1/linear_probe.png" alt="Image 2"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_1/image_transformer.png" alt="Image 3"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_1/scene_transformer.png" alt="Image 4"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_1/ground_truth.png" alt="Image 5"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_2/original.png" alt="Image 1"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_2/linear_probe.png" alt="Image 2"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_2/image_transformer.png" alt="Image 3"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_2/scene_transformer.png" alt="Image 4"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_2/ground_truth.png" alt="Image 4"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_3/original.png" alt="Image 1"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_3/linear_probe.png" alt="Image 2"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_3/image_transformer.png" alt="Image 3"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_3/scene_transformer.png" alt="Image 4"></div>
        <div class="grid-item"><img src="./static/images/multi_view_segmentation/scannet_3/ground_truth.png" alt="Image 4"></div>
        <!-- Add more images as needed -->
    </div>
    <br>
    <br>
    <h2 class="title is-3">One-Shot Object Retrieval</h2>
      <p>We introduce a new task called object retrieval where the goal is to find all instances of an object in an image colection.  We compare object queries to individual regions from an image. In the examples below, the third column shows the similarity between the highlighted object in the first column and the database image.</p>
      <div class="grid-container-2">
        <div class="grid-header">Query Image</div>
        <div class="grid-header">Database Image</div>
        <div class="grid-header">Heatmap</div>
        <div class="grid-item-2"><img src="./static/images/object_retrieval/apple_query.jpg" alt="Image 1" ></div>
        <div class="grid-item-2"><img src="./static/images/object_retrieval/apple_database.jpg" alt="Image 2"></div>
        <div class="grid-item-2"><img src="./static/images/object_retrieval/apple_heatmap.jpg" alt="Image 3"></div>
        <div class="grid-item-2"><img src="./static/images/object_retrieval/banana_query.jpg" alt="Image 4"></div>
        <div class="grid-item-2"><img src="./static/images/object_retrieval/banana_database.jpg"  alt="Image 1"></div>
        <div class="grid-item-2"><img src="./static/images/object_retrieval/banana_heatmap.jpg" alt="Image 2"></div>
        <div class="grid-item-2"><img src="./static/images/object_retrieval/train_query.jpg"alt="Image 3"></div>
        <div class="grid-item-2"><img src="./static/images/object_retrieval/train_database.jpg"  alt="Image 4"></div>
        <div class="grid-item-2"><img src="./static/images/object_retrieval/train_heatmap.jpg" alt="Image 4"></div>
        <!-- Add more images as needed -->
    </div>
    <br>
    <br>
    <h2 class="title is-3">Activity Classification</h2>
      <p>The last application is multi-frame activity classification. Similar to multi-view segmentation, we train a transformer on top of per-frame region features.</p>
      <img src="./static/images/activity_classification.jpg" alt="Description of the image",class="center-margin">

    </div>
    </div>
</section>
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{regions,
      author = {M. Shlapentokh-Rothman*, and Blume*, Ansel and Xiao, Yao and Wu, Yuqun and TV, Sethuraman and Tao, Heyi and Lee, Jae Yong and Torres, Wilfredo and Wang, Yu-Xiong and Hoiem, Derek},
      title = {Region-Based Representations Revisited},
      booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
      year = {2024}
  }</code></pre>
  </div>
</section>

<section>

   



          <p>Website is based on template from <a href="https://nerfies.github.io/">Nerfies</a> </p>
       



</section>


<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>



 
  
 


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">


      <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>


      <-- Matting. 
      <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    < Matting. 

    <Animation. 
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2>

        < Interpolating. 
        <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>
        </ Interpolating. 

        <Re-rendering. 
        <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div>
        </ Re-rendering.

      </div>
    </div>
    </ Animation. 


    Concurrent Work. 
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div>
    </ Concurrent Work. 

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->

</body>
</html>